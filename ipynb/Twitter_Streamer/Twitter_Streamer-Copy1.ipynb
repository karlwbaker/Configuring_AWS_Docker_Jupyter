{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pip` to install `twitter`.\n",
    "\n",
    "Use \"!\" at beginning of line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter in /opt/conda/lib/python3.6/site-packages (1.18.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `TwitterStream` and `OAuth` from `twitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "from twitter import TwitterStream, OAuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `oauth`\n",
    "Authentication protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new object called `oauth` using `OAuth`. \n",
    "\n",
    "    OAuth(token, token_secret, consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '2379975860-fvNwQM9Kk9bL4A6AyTNdGSSJAKuE9dDnTEISg3q' # access token\n",
    "token_secret = 'JPYjiwcOWnGy6nuJEvDt9owkKaQvXcvN2sryA8wl3kQxL' # access token secre\n",
    "consumer_key = 'iJm4IBd4wmfJJjOTvQiMOrEXf'\n",
    "consumer_secret = '9a4G3kwY1w3OmekWdmQGMo2nxLuxTxttjDQrfsRuvI9rUv29O6'   # API secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oauth = OAuth(token, token_secret, consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new object called `twitter_stream` using `TwitterStream`.\n",
    "\n",
    "Use the argument `auth=oauth` referencing the `oauth` object you just made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `twitter_stream`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_stream = TwitterStream(auth= oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `bounding_box`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a string called `bounding_box`. The string should contain the geo-coordinates of a bounding box separated by commas. These values are for Santa Monica:\n",
    "\n",
    "    -118.5137323688,34.0001996344,-118.4702449172,34.0331651696\n",
    "    \n",
    "You can make your own here: https://boundingbox.klokantech.com. Be sure to specify CSV RAW to get the values in this format.\n",
    "\n",
    "![](https://www.evernote.com/l/AAH3H9KGE6hD9JpPJPFncw09exRyoYSid5IB/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box = '-118.5137323688,34.0001996344,-118.4702449172,34.0331651696' # Santa Monica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tweet_iterator`\n",
    "\n",
    "Create an object called `tweet_iterator`. \n",
    "\n",
    "1. Use `twitter_stream`. # NOT the full fire hose. Maybe 1 in 8 tweets. Paid subscription for ALL tweets.\n",
    "1. Apply `.statuses` to grab statuses.\n",
    "1. Apply a `.filter()` with the argument `locations=bounding_box`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_iterator = (twitter_stream\n",
    "                  .statuses\n",
    "                  .filter(locations=bounding_box))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the next value from the `tweet_iterator` and store it as the variable `this_tweet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_tweet = next(tweet_iterator)\n",
    "# this_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is the type of `this_tweet`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(this_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the keys of `this_tweet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_tweet.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the `text` and `user` of `this_tweet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_tweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_tweet['user']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tweets\n",
    "\n",
    "Create an empty list called `tweets`.\n",
    "\n",
    "Use a `for`-loop to collect ten tweets and add them to this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = []\n",
    "# for i in range(10):\n",
    "#     tweets.append(next(tweet_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `tweets` in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df = pd.DataFrame(tweets)\n",
    "# tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display just the text of the tweets using DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the type of `tweets`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for obj in [tweets, tweet_iterator, tweets_df]:\n",
    "#     print(type(obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a list comprehension to display the type of each of the objects in `tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [type(obj) for obj in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `json` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object called `tweets_string` using `json.dumps()`.\n",
    "\n",
    "Display the first 500 characters of this string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_string = json.dumps(tweets)\n",
    "# tweets_string[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Tweets to Disk\n",
    "\n",
    "Using this pattern\n",
    "\n",
    "    with open(filename_as_string, 'w') as outfile:\n",
    "        json.dump(python_object, outfile)\n",
    "        \n",
    "write `tweets` to disk as json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    timestamp_str = str(datetime.now())\n",
    "    timestamp_str = (timestamp_str.replace(' ', '_')\n",
    "                                  .replace('.', '-')\n",
    "                                  .replace(':', '-'))\n",
    "    return timestamp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tweets_to_disk(hundred_tweets):\n",
    "    timestamp_str = get_timestamp()\n",
    "    print('tweets_' + timestamp_str + '.json')\n",
    "    with open('tweets_' + timestamp_str + '.json', 'w') as outfile:\n",
    "        json.dump(hundred_tweets, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Tweets from Disk\n",
    "\n",
    "Using this pattern\n",
    "\n",
    "    with open(filename_as_string) as infile:\n",
    "        json_data=infile.read()\n",
    "        python_object_from_disk = json.loads(json_data)\n",
    "        \n",
    "read the tweets from the json. Store them as `tweets_from_disk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tweets.json') as infile:\n",
    "#     json_data = infile.read()\n",
    "#     tweets_from_disk = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `tweets_from_disk` as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_from_disk_df = pd.DataFrame(tweets_from_disk)\n",
    "# tweets_from_disk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect as many tweets as possible 7/19 to 7/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_2018-07-21_19-40-10-489813.json\n",
      "tweets_2018-07-21_19-40-20-973734.json\n",
      "tweets_2018-07-21_19-40-34-835311.json\n",
      "tweets_2018-07-21_19-40-44-313050.json\n",
      "tweets_2018-07-21_19-40-54-814445.json\n",
      "tweets_2018-07-21_19-41-07-857931.json\n",
      "tweets_2018-07-21_19-41-22-173816.json\n",
      "tweets_2018-07-21_19-41-35-877586.json\n",
      "tweets_2018-07-21_19-41-44-987886.json\n",
      "tweets_2018-07-21_19-42-01-640357.json\n",
      "tweets_2018-07-21_19-42-05-676083.json\n",
      "tweets_2018-07-21_19-42-14-527292.json\n",
      "tweets_2018-07-21_19-42-25-406544.json\n",
      "tweets_2018-07-21_19-42-48-950429.json\n",
      "tweets_2018-07-21_19-43-04-960873.json\n",
      "tweets_2018-07-21_19-43-15-916800.json\n",
      "tweets_2018-07-21_19-43-34-439992.json\n",
      "tweets_2018-07-21_19-43-46-181447.json\n",
      "tweets_2018-07-21_19-44-01-946708.json\n",
      "tweets_2018-07-21_19-44-11-869082.json\n",
      "tweets_2018-07-21_19-44-29-007667.json\n",
      "tweets_2018-07-21_19-44-44-265632.json\n",
      "tweets_2018-07-21_19-44-59-050657.json\n",
      "tweets_2018-07-21_19-45-14-838993.json\n",
      "tweets_2018-07-21_19-45-23-823965.json\n",
      "tweets_2018-07-21_19-45-36-321194.json\n",
      "tweets_2018-07-21_19-45-47-769160.json\n",
      "tweets_2018-07-21_19-45-56-000651.json\n",
      "tweets_2018-07-21_19-46-10-614148.json\n",
      "tweets_2018-07-21_19-46-22-577701.json\n",
      "tweets_2018-07-21_19-46-33-286339.json\n",
      "tweets_2018-07-21_19-46-43-691859.json\n",
      "tweets_2018-07-21_19-47-03-920408.json\n",
      "tweets_2018-07-21_19-47-14-207957.json\n",
      "tweets_2018-07-21_19-47-24-057785.json\n",
      "tweets_2018-07-21_19-47-37-652211.json\n",
      "tweets_2018-07-21_19-48-05-456036.json\n",
      "tweets_2018-07-21_19-48-17-783595.json\n",
      "tweets_2018-07-21_19-48-28-334743.json\n",
      "tweets_2018-07-21_19-48-39-763494.json\n",
      "tweets_2018-07-21_19-48-57-453808.json\n",
      "tweets_2018-07-21_19-49-15-972681.json\n",
      "tweets_2018-07-21_19-49-28-966007.json\n",
      "tweets_2018-07-21_19-49-38-408288.json\n",
      "tweets_2018-07-21_19-49-50-310078.json\n",
      "tweets_2018-07-21_19-50-02-730045.json\n",
      "tweets_2018-07-21_19-50-14-663811.json\n",
      "tweets_2018-07-21_19-50-32-708091.json\n",
      "tweets_2018-07-21_19-50-48-593144.json\n",
      "tweets_2018-07-21_19-50-58-732949.json\n",
      "tweets_2018-07-21_19-51-13-652118.json\n",
      "tweets_2018-07-21_19-51-26-914286.json\n",
      "tweets_2018-07-21_19-51-35-589588.json\n",
      "tweets_2018-07-21_19-51-45-233136.json\n",
      "tweets_2018-07-21_19-51-54-227112.json\n",
      "tweets_2018-07-21_19-52-12-786512.json\n",
      "tweets_2018-07-21_19-52-29-816347.json\n",
      "tweets_2018-07-21_19-52-40-322940.json\n",
      "tweets_2018-07-21_19-52-58-448158.json\n",
      "tweets_2018-07-21_19-53-11-590388.json\n",
      "tweets_2018-07-21_19-53-23-456329.json\n",
      "tweets_2018-07-21_19-53-33-501305.json\n",
      "tweets_2018-07-21_19-53-50-785283.json\n",
      "tweets_2018-07-21_19-54-09-707398.json\n",
      "tweets_2018-07-21_19-54-20-390471.json\n",
      "tweets_2018-07-21_19-54-32-982883.json\n",
      "tweets_2018-07-21_19-54-45-249407.json\n",
      "tweets_2018-07-21_19-54-55-883175.json\n",
      "tweets_2018-07-21_19-55-07-932857.json\n",
      "tweets_2018-07-21_19-55-24-545433.json\n",
      "tweets_2018-07-21_19-55-47-543314.json\n",
      "tweets_2018-07-21_19-56-02-577802.json\n",
      "tweets_2018-07-21_19-56-18-711940.json\n",
      "tweets_2018-07-21_19-56-26-126788.json\n",
      "tweets_2018-07-21_19-56-39-174301.json\n",
      "tweets_2018-07-21_19-56-47-495575.json\n",
      "tweets_2018-07-21_19-57-05-708092.json\n",
      "tweets_2018-07-21_19-57-14-879318.json\n",
      "tweets_2018-07-21_19-57-33-519462.json\n",
      "tweets_2018-07-21_19-57-48-662043.json\n",
      "tweets_2018-07-21_19-58-05-052132.json\n",
      "tweets_2018-07-21_19-58-18-714246.json\n",
      "tweets_2018-07-21_19-58-28-417285.json\n",
      "tweets_2018-07-21_19-58-37-009834.json\n",
      "tweets_2018-07-21_19-58-52-019856.json\n",
      "tweets_2018-07-21_19-59-00-606835.json\n",
      "tweets_2018-07-21_19-59-19-405472.json\n",
      "tweets_2018-07-21_19-59-34-300905.json\n",
      "tweets_2018-07-21_19-59-41-344839.json\n",
      "tweets_2018-07-21_19-59-50-835647.json\n",
      "tweets_2018-07-21_20-00-12-709291.json\n",
      "tweets_2018-07-21_20-00-22-671607.json\n",
      "tweets_2018-07-21_20-00-39-582565.json\n",
      "tweets_2018-07-21_20-00-57-032958.json\n",
      "tweets_2018-07-21_20-01-06-135492.json\n",
      "tweets_2018-07-21_20-01-22-312334.json\n",
      "tweets_2018-07-21_20-01-32-398685.json\n",
      "tweets_2018-07-21_20-01-50-060844.json\n",
      "tweets_2018-07-21_20-02-05-927077.json\n",
      "tweets_2018-07-21_20-02-22-569705.json\n",
      "tweets_2018-07-21_20-02-31-251549.json\n",
      "tweets_2018-07-21_20-02-37-271560.json\n",
      "tweets_2018-07-21_20-02-46-778078.json\n",
      "tweets_2018-07-21_20-03-05-172120.json\n",
      "tweets_2018-07-21_20-03-15-465551.json\n",
      "tweets_2018-07-21_20-03-34-571584.json\n",
      "tweets_2018-07-21_20-03-46-094565.json\n",
      "tweets_2018-07-21_20-03-52-693987.json\n",
      "tweets_2018-07-21_20-04-12-307760.json\n",
      "tweets_2018-07-21_20-04-23-129828.json\n",
      "tweets_2018-07-21_20-04-37-027008.json\n",
      "tweets_2018-07-21_20-04-44-132163.json\n",
      "tweets_2018-07-21_20-04-50-569356.json\n",
      "tweets_2018-07-21_20-05-02-829632.json\n",
      "tweets_2018-07-21_20-05-09-194641.json\n",
      "tweets_2018-07-21_20-05-24-289614.json\n",
      "tweets_2018-07-21_20-05-39-492838.json\n",
      "tweets_2018-07-21_20-05-50-097248.json\n",
      "tweets_2018-07-21_20-06-11-985228.json\n",
      "tweets_2018-07-21_20-06-23-693618.json\n",
      "tweets_2018-07-21_20-06-42-170610.json\n",
      "tweets_2018-07-21_20-06-55-593939.json\n",
      "tweets_2018-07-21_20-07-07-986279.json\n",
      "tweets_2018-07-21_20-07-21-194546.json\n",
      "tweets_2018-07-21_20-07-28-955079.json\n",
      "tweets_2018-07-21_20-07-50-632846.json\n",
      "tweets_2018-07-21_20-08-00-000705.json\n",
      "tweets_2018-07-21_20-08-11-781698.json\n",
      "tweets_2018-07-21_20-08-17-544138.json\n",
      "tweets_2018-07-21_20-08-31-190495.json\n",
      "tweets_2018-07-21_20-08-45-807389.json\n",
      "tweets_2018-07-21_20-08-52-807774.json\n",
      "tweets_2018-07-21_20-09-04-128010.json\n",
      "tweets_2018-07-21_20-09-18-214214.json\n",
      "tweets_2018-07-21_20-09-29-427725.json\n",
      "tweets_2018-07-21_20-09-45-528661.json\n",
      "tweets_2018-07-21_20-09-59-669845.json\n",
      "tweets_2018-07-21_20-10-08-350804.json\n",
      "tweets_2018-07-21_20-10-27-101442.json\n",
      "tweets_2018-07-21_20-10-35-777993.json\n",
      "tweets_2018-07-21_20-10-51-119496.json\n",
      "tweets_2018-07-21_20-11-07-766694.json\n",
      "tweets_2018-07-21_20-11-15-301585.json\n",
      "tweets_2018-07-21_20-11-34-832809.json\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-85b9adbb4ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# collect tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhundred_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# every 100 tweets write to disk, then continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/twitter/stream.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# Decode all the things:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mHangup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/twitter/stream.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mready_to_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mready_to_read\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# Code 2 is error from a non-blocking read of an empty buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "# counter = count(0)\n",
    "counter = 0\n",
    "hundred_tweets = []\n",
    "\n",
    "while True:\n",
    "    # next(counter)\n",
    "    counter += 1\n",
    "    \n",
    "    # collect tweets\n",
    "    hundred_tweets.append(next(tweet_iterator))\n",
    "    \n",
    "    # every 100 tweets write to disk, then continue\n",
    "    if counter == 10:                                            # TEST: WRITE TO DISK EVERY 10 TWEETS\n",
    "        write_tweets_to_disk(hundred_tweets)\n",
    "        # counter = count(0)\n",
    "        counter = 0\n",
    "        hundred_tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
